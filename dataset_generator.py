import pandas as pd
import random
from utils import calculate_team_kpi, calculate_individual_kpi, calculate_commit_complexity


def generate_team_metrics(num_samples: int = 1000) -> pd.DataFrame:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ KPI,
    –∏—Å–ø–æ–ª—å–∑—É—è —É–ª—É—á—à–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ preprocess.py.
    """
    data = []

    for _ in range(num_samples):
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
        team_size = random.randint(2, 15)
        commits_total = random.randint(50, 500)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–º–º–∏—Ç—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏
        feature_commits = random.randint(int(commits_total * 0.3), int(commits_total * 0.6))  # 30-60%
        fix_commits = random.randint(int(commits_total * 0.1), int(commits_total * 0.3))  # 10-30%
        refactor_commits = random.randint(int(commits_total * 0.05), int(commits_total * 0.2))  # 5-20%
        test_commits = random.randint(int(commits_total * 0.05), int(commits_total * 0.15))  # 5-15%
        docs_commits = random.randint(int(commits_total * 0.02), int(commits_total * 0.1))  # 2-10%

        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–º–∏—Ç–æ–≤
        actual_total = feature_commits + fix_commits + refactor_commits + test_commits + docs_commits
        if actual_total > commits_total:
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
            scale = commits_total / actual_total
            feature_commits = int(feature_commits * scale)
            fix_commits = int(fix_commits * scale)
            refactor_commits = int(refactor_commits * scale)
            test_commits = int(test_commits * scale)
            docs_commits = commits_total - (feature_commits + fix_commits + refactor_commits + test_commits)

        # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
        refactor_ratio = refactor_commits / commits_total if commits_total > 0 else 0
        fix_ratio = fix_commits / commits_total if commits_total > 0 else 0
        feature_ratio = feature_commits / commits_total if commits_total > 0 else 0
        docs_ratio = docs_commits / commits_total if commits_total > 0 else 0
        test_ratio = test_commits / commits_total if commits_total > 0 else 0

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        merge_conflicts = random.randint(0, min(20, commits_total // 25))  # –ö–æ–Ω—Ñ–ª–∏–∫—Ç—ã –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        active_days = random.randint(max(10, commits_total // 10), 365)  # –ê–∫—Ç–∏–≤–Ω—ã–µ –¥–Ω–∏ —Å–≤—è–∑–∞–Ω—ã —Å –∫–æ–º–º–∏—Ç–∞–º–∏
        avg_commits_per_dev = commits_total / team_size if team_size > 0 else 0

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é —Å—Ä–µ–¥–Ω—é—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        avg_complexity = random.uniform(0.8, 2.5)  # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

        # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π bus factor (1-5, –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã)
        if team_size <= 2:
            bus_factor = random.randint(1, 2)
        else:
            bus_factor = random.randint(2, min(5, team_size))

        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ KPI
        team_data = {
            'commits_total': commits_total,
            'merge_conflicts': merge_conflicts,
            'bus_factor': bus_factor,
            'refactor_commits': refactor_commits,
            'fix_commits': fix_commits,
            'feature_commits': feature_commits,
            'docs_commits': docs_commits,
            'test_commits': test_commits,
            'refactor_ratio': refactor_ratio,
            'fix_ratio': fix_ratio,
            'feature_ratio': feature_ratio,
            'docs_ratio': docs_ratio,
            'test_ratio': test_ratio,
            'active_days': active_days,
            'team_size': team_size,
            'avg_commits_per_dev': avg_commits_per_dev,
            'avg_complexity': avg_complexity  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫
        }

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–º–∞–Ω–¥–Ω—ã–π KPI –∏—Å–ø–æ–ª—å–∑—É—è —É–ª—É—á—à–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        kpi_score = calculate_team_kpi(team_data)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –¥–∞—Ç–∞—Å–µ—Ç
        data.append({
            **team_data,
            'kpi_score': kpi_score
        })

    return pd.DataFrame(data)


def generate_individual_metrics(num_samples: int = 1000) -> pd.DataFrame:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    —Å —É—á–µ—Ç–æ–º –Ω–æ–≤—ã—Ö —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª.
    """
    data = []

    for _ in range(num_samples):
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
        commits_total = random.randint(10, 200)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–º–º–∏—Ç—ã —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏
        feature_commits = random.randint(int(commits_total * 0.2), int(commits_total * 0.5))
        fix_commits = random.randint(int(commits_total * 0.1), int(commits_total * 0.3))
        refactor_commits = random.randint(int(commits_total * 0.05), int(commits_total * 0.15))
        test_commits = random.randint(int(commits_total * 0.05), int(commits_total * 0.2))
        docs_commits = random.randint(int(commits_total * 0.02), int(commits_total * 0.1))

        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        actual_total = feature_commits + fix_commits + refactor_commits + test_commits + docs_commits
        if actual_total > commits_total:
            scale = commits_total / actual_total
            feature_commits = int(feature_commits * scale)
            fix_commits = int(fix_commits * scale)
            refactor_commits = int(refactor_commits * scale)
            test_commits = int(test_commits * scale)
            docs_commits = commits_total - (feature_commits + fix_commits + refactor_commits + test_commits)

        # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
        feature_ratio = feature_commits / commits_total if commits_total > 0 else 0
        fix_ratio = fix_commits / commits_total if commits_total > 0 else 0
        refactor_ratio = refactor_commits / commits_total if commits_total > 0 else 0
        test_ratio = test_commits / commits_total if commits_total > 0 else 0
        docs_ratio = docs_commits / commits_total if commits_total > 0 else 0

        active_days = random.randint(max(5, commits_total // 5), 180)

        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∫–æ–º–º–∏—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –≤–µ—Ç–∫–∞–º–∏
        commits = []

        # –°–æ–∑–¥–∞–µ–º –∫–æ–º–º–∏—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        commits.extend(create_commits_with_type("feature", feature_commits))
        commits.extend(create_commits_with_type("fix", fix_commits))
        commits.extend(create_commits_with_type("refactor", refactor_commits))
        commits.extend(create_commits_with_type("test", test_commits))
        commits.extend(create_commits_with_type("docs", docs_commits))

        # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π KPI —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π
        kpi_score = calculate_individual_kpi(commits[:commits_total])  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω—é—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–º–º–∏—Ç–æ–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
        if commits_total > 0:
            total_complexity = sum(calculate_commit_complexity(commit) for commit in commits[:commits_total])
            avg_complexity = total_complexity / commits_total
        else:
            avg_complexity = 1.0

        data.append({
            'commits_total': commits_total,
            'feature_commits': feature_commits,
            'fix_commits': fix_commits,
            'refactor_commits': refactor_commits,
            'test_commits': test_commits,
            'docs_commits': docs_commits,
            'feature_ratio': feature_ratio,
            'fix_ratio': fix_ratio,
            'refactor_ratio': refactor_ratio,
            'test_ratio': test_ratio,
            'docs_ratio': docs_ratio,
            'active_days': active_days,
            'avg_complexity': avg_complexity,  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫
            'kpi_score': kpi_score
        })

    return pd.DataFrame(data)


def create_commits_with_type(commit_type: str, count: int) -> list:
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–º–∏—Ç—ã —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –∏ –≤–µ—Ç–∫–∞–º–∏"""
    if count == 0:
        return []

    commits = []
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å—Å—è improved_classify_commit
    messages = {
        "feature": [
            "feat: add new user authentication system",
            "feature: implement payment gateway integration",
            "add: new dashboard analytics",
            "implement: real-time notifications",
        ],
        "fix": [
            "fix: resolve memory leak in cache",
            "bug: fix login issue on mobile",
            "fix: correct data validation error",
            "resolve: performance regression",
        ],
        "refactor": [
            "refactor: optimize database queries",
            "cleanup: remove deprecated code",
            "refactor: improve code structure",
            "optimize: reduce bundle size",
        ],
        "test": [
            "test: add unit tests for auth service",
            "spec: integration tests for API",
            "test: coverage for payment module",
            "test: e2e tests for user flow",
        ],
        "docs": [
            "docs: update API documentation",
            "readme: add installation guide",
            "docs: code comments cleanup",
            "document: architecture decisions",
        ]
    }

    # –í–µ—Ç–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    release_branches = ["main", "master", "release/7.1", "release/7.2", "production"]
    feature_branches = ["feature/login", "feature/payment", "develop", "feature/api", "feature/ui"]

    for i in range(count):
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        message = random.choice(messages[commit_type])

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä –∑–∞–¥–∞—á–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é (–¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏)
        has_task = random.random() < 0.4
        if has_task:
            message += f" (#{random.randint(1000, 9999)})"

        # –í—ã–±–∏—Ä–∞–µ–º –≤–µ—Ç–∫—É (—Ä–µ–ª–∏–∑–Ω—ã–µ –≤–µ—Ç–∫–∏ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å)
        is_release = random.random() < 0.25
        branches = [random.choice(release_branches if is_release else feature_branches)]

        # –°–æ–∑–¥–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª–µ–π –¥–ª—è –∫–æ–º–º–∏—Ç–∞ (merge –∫–æ–º–º–∏—Ç—ã –∏–º–µ—é—Ç 2+ —Ä–æ–¥–∏—Ç–µ–ª–µ–π)
        parents = []
        if random.random() < 0.1:  # 10% –∫–æ–º–º–∏—Ç–æ–≤ - merge –∫–æ–º–º–∏—Ç—ã
            parents = ["parent1", "parent2"]
        else:
            parents = ["parent1"]

        commits.append({
            "message": message,
            "branches": branches,
            "parents": parents  # –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª–µ–π –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        })

    return commits


def analyze_dataset_quality(df: pd.DataFrame, dataset_type: str):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print(f"\nüìà –ê–Ω–∞–ª–∏–∑ {dataset_type} –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"   –†–∞–∑–º–µ—Ä: {len(df)} samples")
    print(f"   KPI –¥–∏–∞–ø–∞–∑–æ–Ω: {df['kpi_score'].min():.2f} - {df['kpi_score'].max():.2f}")
    print(f"   –°—Ä–µ–¥–Ω–∏–π KPI: {df['kpi_score'].mean():.2f} ¬± {df['kpi_score'].std():.2f}")

    # –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–∫–æ–π –ø—Ä–∏–∑–Ω–∞–∫
    if 'avg_complexity' in df.columns:
        print(f"   –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {df['avg_complexity'].mean():.2f} ¬± {df['avg_complexity'].std():.2f}")

    # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è KPI
    kpi_ranges = [(0, 20), (20, 40), (40, 60), (60, 80), (80, 100)]
    for low, high in kpi_ranges:
        count = len(df[(df['kpi_score'] >= low) & (df['kpi_score'] < high)])
        percentage = (count / len(df)) * 100
        print(f"   KPI {low}-{high}: {count} samples ({percentage:.1f}%)")

    return df


if __name__ == "__main__":
    print("üöÄ Generating improved datasets for dual model training...")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    print("\nüìä Generating team KPI dataset...")
    team_df = generate_team_metrics(50000)  # –£–º–µ–Ω—å—à–∏–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏, –º–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å 50000
    team_df = analyze_dataset_quality(team_df, "Team")
    team_df.to_csv("data/team_kpi_dataset.csv", index=False)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    print("\nüë§ Generating individual KPI dataset...")
    individual_df = generate_individual_metrics(50000)  # –£–º–µ–Ω—å—à–∏–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    individual_df = analyze_dataset_quality(individual_df, "Individual")
    individual_df.to_csv("data/individual_kpi_dataset.csv", index=False)

    print("\nüìã Final dataset summary:")
    print(f"‚úÖ Team dataset: {len(team_df)} samples")
    print(f"‚úÖ Individual dataset: {len(individual_df)} samples")

    print("\nüîç Sample team data:")
    print(team_df[['commits_total', 'team_size', 'feature_ratio', 'fix_ratio', 'avg_complexity', 'kpi_score']].head())

    print("\nüîç Sample individual data:")
    print(individual_df[['commits_total', 'feature_ratio', 'fix_ratio', 'avg_complexity', 'kpi_score']].head())