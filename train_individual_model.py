import pandas as pd
import joblib
import yaml
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
from pathlib import Path
import numpy as np

CONFIG_PATH = Path("configs/config.yaml")


def load_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥ YAML"""
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)
    return cfg


def train_individual_model():
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ KPI –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞.
    """
    cfg = load_config()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ KPI
    df = pd.read_csv("data/individual_kpi_dataset.csv")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    required_features = [
        'commits_total', 'feature_commits', 'fix_commits', 'refactor_commits',
        'test_commits', 'docs_commits', 'feature_ratio', 'fix_ratio',
        'refactor_ratio', 'test_ratio', 'docs_ratio', 'active_days',
        'avg_complexity'  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫
    ]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    for feature in required_features:
        if feature not in df.columns:
            print(f"‚ö†Ô∏è  –ü—Ä–∏–∑–Ω–∞–∫ {feature} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, —Å–æ–∑–¥–∞–µ–º...")
            if feature == 'avg_complexity':
                df['avg_complexity'] = 1.0  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            else:
                df[feature] = 0

    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ KPI
    individual_features = required_features

    X = df[individual_features]
    y = df['kpi_score']

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ NaN –∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º:")
    print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å X: {X.shape}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ NaN –≤ X: {X.isna().sum().sum()}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ NaN –≤ y: {y.isna().sum()}")
    print(f"–î–∏–∞–ø–∞–∑–æ–Ω KPI: {y.min():.2f} - {y.max():.2f}")

    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
    y = y.fillna(0)

    # –î–µ–ª–∏–º –Ω–∞ train/test —Å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=cfg["data"].get("test_size", 0.2),
        random_state=cfg["model"].get("random_state", 42),
        stratify=pd.cut(y, bins=5, labels=range(5))  # –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ KPI
    )

    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ KPI
    individual_model = RandomForestRegressor(
        n_estimators=cfg["model"].get("n_estimators", 150),
        max_depth=cfg["model"].get("max_depth", 10),
        min_samples_split=cfg["model"].get("min_samples_split", 3),
        min_samples_leaf=cfg["model"].get("min_samples_leaf", 1),
        random_state=cfg["model"].get("random_state", 42),
        n_jobs=-1
    )

    # –û–±—É—á–∞–µ–º
    print("üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    individual_model.fit(X_train, y_train)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–µ
    y_pred = individual_model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    print(f"\nüìä Individual Model Performance:")
    print(f"R¬≤: {r2:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"RMSE: {np.sqrt(np.mean((y_test - y_pred) ** 2)):.4f}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    individual_model_path = "models/individual_kpi_regressor.pkl"
    Path(individual_model_path).parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(individual_model, individual_model_path)
    print(f"‚úÖ Individual –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {individual_model_path}")

    # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ train –∏ test
    train_score = individual_model.score(X_train, y_train)
    test_score = individual_model.score(X_test, y_test)
    print(f"R¬≤ train: {train_score:.4f}")
    print(f"R¬≤ test: {test_score:.4f}")
    print(f"–†–∞–∑–Ω–∏—Ü–∞: {train_score - test_score:.4f}")

    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importance = pd.DataFrame({
        'feature': individual_features,
        'importance': individual_model.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"\nüîù –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for _, row in feature_importance.head(10).iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
    feature_info = {
        "model_type": "individual_kpi",
        "features": individual_features,
        "target": "kpi_score",
        "performance": {
            "r2_score": float(r2),
            "mae": float(mae),
            "train_r2": float(train_score),
            "test_r2": float(test_score)
        },
        "feature_importance": feature_importance.to_dict('records')
    }

    import json
    with open("models/individual_model_info.json", "w") as f:
        json.dump(feature_info, f, indent=2)

    return individual_model, individual_features


if __name__ == "__main__":
    train_individual_model()